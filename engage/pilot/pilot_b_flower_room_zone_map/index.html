<!-- /pilots/flower-room-zone-map/index.html -->
<!doctype html>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-V2474V50XP"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-V2474V50XP');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />

    <title>Pilot B — Flower Room Zone Map | HermodLabs</title>
    <meta
      name="description"
      content="In ~30 days, map flower-room microclimate zones across triggers, run 2–3 targeted intervention tests, and prove the fix with pass/fail evidence + validity gating + receipts."
    />

    <script type="importmap">
    { "imports": { "lit": "https://esm.run/lit" } }
    </script>

    <link rel="stylesheet" href="" id="main-css" />
    <script type="module" src="../../../bootstrap.js"></script>
  </head>

  <body>
    <site-page>
      <section class="pilots pilots--detail" aria-labelledby="pilot-title">
        <div class="pilots__inner">
          <header class="pilots__header">
            <h1 class="pilots__title" id="pilot-title">Pilot B — Flower Room Zone Map</h1>

            <!-- Simple, direct value proposition up front -->
            <p class="pilots__lede">
              In ~30 days, find the worst flower-room pockets, test fixes, and prove the improvement holds across real triggers (night, irrigation, dehu/HVAC).
            </p>

            <!-- Strong CTA up front -->
            <div class="pilots__actions" aria-label="Pilot B primary actions">
              <a class="button button--primary" href="/pilots#apply">Request Pilot B</a>
              <a class="button button--secondary" href="/contact">Contact</a>
              <a class="button button--secondary" href="#deliverables-title">See deliverables</a>
            </div>

            <p class="pilots__subhead">
              A month-scale pilot built around the operational reality of flower: cycle-trigger events, night swings,
              irrigation transitions, and dehu/HVAC limits. We don’t just map—we verify.
            </p>

            <!-- Problem / Solution / Impact breakpoints (business-first) -->
            <ul class="pilots__list" aria-label="Pilot B quick overview">
              <li class="pilots__list-item">
                <strong>Problem:</strong> Flower risk concentrates in canopy microclimates that room averages can hide—especially across trigger windows.
              </li>
              <li class="pilots__list-item">
                <strong>Solution:</strong> Zone maps + repeatability scoring + 2–3 intervention tests with pass/fail criteria (only in safe-to-interpret windows).
              </li>
              <li class="pilots__list-item">
                <strong>Impact:</strong> Faster root-cause isolation, fewer “one lucky day” conclusions, and targeted interventions that your team can execute in production.
              </li>
            </ul>

            <!-- Validation signals (credibility up front) -->
            <div class="pilots__note" role="note" aria-label="Pilot B validation signals">
              <p class="pilots__fineprint">
                <strong>Validation signals:</strong> includes <strong>trigger coverage</strong> (lights/irrigation/night/dehu/HVAC),
                <strong>repeatability scoring</strong>, <strong>pass/fail evidence packages</strong>, <strong>validity gating</strong> (CONFIDENT vs ABSTAIN),
                and <strong>receipts</strong> (IDs/versions/config/calibration state) for defensible handoff.
              </p>
            </div>

            <div class="pilots__note" role="note" aria-label="Platform status and scope note">
              <p class="pilots__fineprint">
                <strong>Platform status / scope note:</strong> This pilot page reflects the current Pilot B operating approach and report format.
                Outputs, UI screens, terminology, and acceptance tests may evolve; any engagement is governed by the statement of work and
                acceptance criteria agreed for your site.
              </p>
            </div>
          </header>

          <!-- New: fast business clarity -->
          <section class="pilots__section" aria-labelledby="know-title">
            <h2 class="pilots__heading" id="know-title">What you’ll know (fast)</h2>
            <ul class="pilots__list">
              <li class="pilots__list-item"><strong>Where the worst zones are:</strong> ranked pockets by persistence + severity + timing.</li>
              <li class="pilots__list-item"><strong>Whether it’s structural:</strong> repeatability under comparable triggers (not noise).</li>
              <li class="pilots__list-item"><strong>Which fix actually works:</strong> 2–3 intervention tests with pass/fail criteria.</li>
              <li class="pilots__list-item"><strong>Whether it holds in real ops:</strong> verification across trigger windows with validity gating.</li>
            </ul>
          </section>

          <section class="pilots__section" aria-labelledby="why-title">
            <h2 class="pilots__heading" id="why-title">Why this matters in flower</h2>
            <ul class="pilots__list">
              <li class="pilots__list-item">
                PM and botrytis risk is tightly coupled to humidity dynamics and airflow—exactly what diverges inside dense canopies.
              </li>
              <li class="pilots__list-item">
                Peer-reviewed cannabis literature reports rapid Botrytis damage under high RH (e.g., &gt;70%) at moderate temperatures,
                which canopy microclimates can reach even when room averages look “safe.”
              </li>
              <li class="pilots__list-item">
                Flower runs on triggers: lights, irrigation, night control, dehu cycles, and HVAC limits. Pilot B is designed to measure the room
                <strong>across those triggers</strong> and prove whether fixes hold beyond one lucky day.
              </li>
            </ul>
          </section>

          <section class="pilots__section" aria-labelledby="deliverables-title">
            <h2 class="pilots__heading" id="deliverables-title">Deliverables</h2>
            <ul class="pilots__list">
              <li class="pilots__list-item"><strong>Pocket catalog:</strong> ranked pockets by persistence + severity + timing</li>
              <li class="pilots__list-item"><strong>Repeatability scoring:</strong> do pockets recur under the same triggers?</li>
              <li class="pilots__list-item"><strong>2–3 intervention tests:</strong> before/after evidence with pass/fail criteria</li>
              <li class="pilots__list-item"><strong>Zone strategy:</strong> recommended airflow/dehu adjustments targeted to zones</li>
              <li class="pilots__list-item"><strong>Receipts + validity:</strong> run receipts + “safe to interpret” windows</li>
            </ul>
          </section>

          <!-- NEW: Case study placeholder section (for future proof points) -->
          <section class="pilots__section" aria-labelledby="case-title">
            <h2 class="pilots__heading" id="case-title">Case study (coming soon)</h2>
            <p class="pilots__text">
              When datasets are ready and customer-approved, we’ll publish short case studies with measurable before/after outcomes
              (e.g., pocket persistence reduction, fewer remediation events, more stable late-flower control across triggers).
            </p>

            <div class="pilots__grid pilots__grid--two">
              <div class="pilot-card">
                <div class="pilot-card__header">
                  <h3 class="pilot-card__title">Example format</h3>
                </div>
                <ul class="pilot-card__list">
                  <li class="pilot-card__item"><strong>Site:</strong> [operation / room size / canopy style]</li>
                  <li class="pilot-card__item"><strong>Problem:</strong> [repeatable night pocket + post-irrigation spike]</li>
                  <li class="pilot-card__item"><strong>Tests:</strong> [air path + dehu strategy + placement change]</li>
                  <li class="pilot-card__item"><strong>Result:</strong> [pocket persistence ↓ X%] (measured in valid windows)</li>
                </ul>
              </div>

              <div class="pilot-card">
                <div class="pilot-card__header">
                  <h3 class="pilot-card__title">Decision-maker takeaway</h3>
                </div>
                <ul class="pilot-card__list">
                  <li class="pilot-card__item">What changed (and why it was rational)</li>
                  <li class="pilot-card__item">How it was verified (repeatability + pass/fail + validity)</li>
                  <li class="pilot-card__item">How to reproduce it (zone strategy + receipts)</li>
                </ul>
              </div>
            </div>
          </section>

          <!-- Uses your real images: asset/img/pilot_b/* -->
          <section class="pilots__section" aria-labelledby="read-title">
            <h2 class="pilots__heading" id="read-title">How to read the deliverables</h2>

            <div class="pilots__grid pilots__grid--two">
              <div class="pilot-card">
                <div class="pilot-card__header">
                  <h3 class="pilot-card__title">Pocket catalog (ranked)</h3>
                </div>
                <p class="pilots__text">
                  Use this to answer: <strong>Which pockets matter most operationally?</strong> Ranking is built from how often it appears (persistence),
                  how bad it gets (severity), and when it hits (timing vs your cycle).
                </p>

                <figure class="pilots__figure">
                  <img
                    class="pilots__img"
                    src="/asset/img/pilot_b/01_pocket_catalog_ranked_pockets_by_persistence_severity%20_timing.png"
                    alt="Pocket catalog ranked by persistence, severity, and timing across typical flower triggers."
                    loading="lazy"
                    decoding="async"
                  />
                  <figcaption class="pilots__fineprint">
                    <strong>Pocket catalog:</strong> Ranked pockets with persistence, severity, and timing cues for triage.
                  </figcaption>
                </figure>

                <p class="pilots__text">
                  Operator pattern: start with the top 1–2 pockets by persistence + severity, align timing to triggers (lights/irrigation/night/dehu),
                  then choose interventions that are realistic in production.
                </p>
              </div>

              <div class="pilot-card">
                <div class="pilot-card__header">
                  <h3 class="pilot-card__title">Repeatability scoring</h3>
                </div>
                <p class="pilots__text">
                  Use this to answer: <strong>Do hotspots recur in the same places under comparable triggers?</strong> Repeatability separates structural
                  problems (air paths, constraints) from noise, and prevents “we fixed it” based on one lucky day.
                </p>

                <figure class="pilots__figure">
                  <img
                    class="pilots__img"
                    src="/asset/img/pilot_b/02_repeatability_scoring_pockets_recur_under_the_same_triggers.png"
                    alt="Repeatability scoring showing whether pocket hotspots recur under the same triggers across comparable cycles."
                    loading="lazy"
                    decoding="async"
                  />
                  <figcaption class="pilots__fineprint">
                    <strong>Repeatability scoring:</strong> Overlays + trigger strips show whether pockets recur under comparable conditions.
                  </figcaption>
                </figure>

                <p class="pilots__text">
                  Decision rule: we only call a pocket “repeatable” when location + rank are broadly stable across comparable cycles and coverage.
                </p>
              </div>

              <div class="pilot-card">
                <div class="pilot-card__header">
                  <h3 class="pilot-card__title">Intervention tests (before/after + pass/fail)</h3>
                </div>
                <p class="pilots__text">
                  Use this to answer: <strong>Did the change measurably improve the pocket zones?</strong> Each test is reported as before/after evidence
                  with pass/fail criteria, and we only claim wins in “safe to interpret” windows.
                </p>

                <figure class="pilots__figure">
                  <img
                    class="pilots__img"
                    src="/asset/img/pilot_b/03_intervention_tests_before_after_pass_fail_criteria.png"
                    alt="Intervention test results showing before and after comparisons with explicit pass/fail criteria for pocket zones."
                    loading="lazy"
                    decoding="async"
                  />
                  <figcaption class="pilots__fineprint">
                    <strong>Intervention tests:</strong> Before/after mapping plus pass/fail cards for each targeted change.
                  </figcaption>
                </figure>

                <p class="pilots__text">
                  Practical use: if a test fails, we don’t “reinterpret” it—we change the intervention and re-verify against the same criteria.
                </p>
              </div>

              <div class="pilot-card">
                <div class="pilot-card__header">
                  <h3 class="pilot-card__title">Zone strategy (what to do next)</h3>
                </div>
                <p class="pilots__text">
                  Use this to answer: <strong>Where should we adjust airflow and dehu strategy—specifically?</strong> The strategy ties recommended actions
                  to the zones that actually drive risk, based on what repeated and what responded to interventions.
                </p>

                <figure class="pilots__figure">
                  <img
                    class="pilots__img"
                    src="/asset/img/pilot_b/04_zone_strategy_targeted_airflow_dehu_adjustments_by_zone.png"
                    alt="Zone strategy map showing targeted airflow and dehumidification adjustments by zone across the flower room."
                    loading="lazy"
                    decoding="async"
                  />
                  <figcaption class="pilots__fineprint">
                    <strong>Zone strategy:</strong> Zone-specific airflow/dehu actions derived from repeated pockets and verified tests.
                  </figcaption>
                </figure>

                <p class="pilots__text">
                  Operator meaning: this is the handoff artifact—clear enough to execute, specific enough to avoid “turn everything down 2% and pray.”
                </p>
              </div>

              <div class="pilot-card">
                <div class="pilot-card__header">
                  <h3 class="pilot-card__title">Receipts + validity (trust-first evidence)</h3>
                </div>
                <p class="pilots__text">
                  Use this to answer: <strong>Can I trust this comparison? What ran, when, and under what conditions?</strong>
                  Receipts record what executed (IDs/versions/config), and validity gating marks when interpretation is earned vs when we abstain.
                </p>

                <figure class="pilots__figure">
                  <img
                    class="pilots__img"
                    src="/asset/img/pilot_b/05_receipts_validity_run_receipts_safe_to_interpret_windows.png"
                    alt="Receipts and validity view showing run receipts and safe-to-interpret windows with abstain segments when conditions are not trustworthy."
                    loading="lazy"
                    decoding="async"
                  />
                  <figcaption class="pilots__fineprint">
                    <strong>Receipts + validity:</strong> Evidence stack + safe-to-interpret windows, with abstain segments when criteria aren’t met.
                  </figcaption>
                </figure>

                <p class="pilots__text">
                  Practical takeaway: if something changed (layout, coverage, calibration, cycle mismatch), the system flags it—so you don’t over-claim wins.
                </p>
              </div>
            </div>
          </section>

          <section class="pilots__section" aria-labelledby="timeline-title">
            <h2 class="pilots__heading" id="timeline-title">Typical timeline (30 days)</h2>
            <ol class="pilots__steps">
              <li class="pilots__step"><strong>Week 1:</strong> install + commissioning + baseline capture (multiple daily windows)</li>
              <li class="pilots__step"><strong>Weeks 2–3:</strong> trigger captures + 2–3 targeted interventions (A/B)</li>
              <li class="pilots__step"><strong>Week 4:</strong> repeatability verification + readout + zone strategy</li>
            </ol>
            <p class="pilots__fineprint">
              Timeline depends on room access and the ability to run comparable trigger windows for verification.
            </p>
          </section>

          <section class="pilots__section" aria-labelledby="acceptance-title">
            <h2 class="pilots__heading" id="acceptance-title">Acceptance tests (examples)</h2>
            <ul class="pilots__list">
              <li class="pilots__list-item">
                <strong>Trigger coverage:</strong> capture across lights, irrigation, night control, and dehu cycles —
                enough to distinguish structural pockets from one-off noise.
              </li>
              <li class="pilots__list-item">
                <strong>Intervention efficacy:</strong> at least one targeted fix shows measurable improvement in the mapped pocket zones —
                using pass/fail criteria rather than “looks better.”
              </li>
              <li class="pilots__list-item">
                <strong>Repeatability:</strong> improvements persist across comparable cycles (not one lucky day) —
                so operators can trust the change in production.
              </li>
              <li class="pilots__list-item">
                <strong>Validity gating:</strong> system abstains when measurement conditions are not trustworthy —
                preventing over-claiming under coverage gaps, mismatched cycles, or stale calibration.
              </li>
            </ul>
          </section>

          <section class="pilots__section" aria-labelledby="faq-title">
            <h2 class="pilots__heading" id="faq-title">FAQ</h2>
            <div class="pilots__grid pilots__grid--two">
              <div class="pilot-card">
                <div class="pilot-card__header">
                  <h3 class="pilot-card__title">Is this “more sensors”?</h3>
                  <p class="pilot-card__summary">
                    No. The point is better interpretation: alignment/validity checks and verification evidence that explain
                    when to trust the reading and whether a change actually worked.
                  </p>
                </div>
              </div>
              <div class="pilot-card">
                <div class="pilot-card__header">
                  <h3 class="pilot-card__title">What changes do you test?</h3>
                  <p class="pilot-card__summary">
                    Typical tests include airflow adjustments, dehu strategy changes, and sensor placement corrections—chosen
                    jointly with the operator and constrained by what’s realistic in production.
                  </p>
                </div>
              </div>
            </div>
          </section>

          <section class="pilots__section pilots__section--sources" aria-labelledby="sources-title">
            <h2 class="pilots__heading" id="sources-title">Sources</h2>
            <ol class="pilots__sources">
              <li class="pilots__source">
                e-GRO — “Powdery Mildew of Hemp (E714)”
                (<a href="https://www.e-gro.org/pdf/E714.pdf" rel="noopener">www.e-gro.org/pdf/E714.pdf</a>)
              </li>
              <li class="pilots__source">
                Canadian Science Publishing (Botany) — “Understanding bud rot development, caused by Botrytis… on cannabis”
                (<a href="https://cdnsciencepub.com/doi/10.1139/cjb-2022-0139" rel="noopener">cdnsciencepub.com/doi/10.1139/cjb-2022-0139</a>)
              </li>
              <li class="pilots__source">
                Colorado State University Extension — “Powdery Mildews”
                (<a href="https://extension.colostate.edu/resource/powdery-mildews/" rel="noopener">extension.colostate.edu/resource/powdery-mildews</a>)
              </li>
            </ol>
          </section>

          <!-- Keep CTA at bottom too (now you have CTA both top + bottom) -->
          <section class="pilots__section" aria-labelledby="cta-title">
            <h2 class="pilots__heading" id="cta-title">Stop re-learning the same room</h2>
            <p class="pilots__text">
              Pilot B is for teams who are done with “tune it until it feels right.” We verify.
            </p>
            <div class="pilots__actions">
              <a class="button button--primary" href="/pilots#apply">Request Pilot B</a>
              <a class="button button--secondary" href="/contact">Contact</a>
            </div>
          </section>
        </div>
      </section>
    </site-page>
  </body>
</html>
