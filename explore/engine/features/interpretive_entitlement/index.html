<!doctype html>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-V2474V50XP"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-V2474V50XP');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />

    <title>HermodLabs — Interpretive Entitlement</title>
    <meta
      name="description"
      content="Interpretive Entitlement formalizes when an interpretation may be asserted and used by requiring explicit warrants, falsifiers, and scope—so actions are permissioned by evidence, not vibes."
    />

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css"
      referrerpolicy="no-referrer"
    />
    <link rel="stylesheet" href="" id="main-css" />
    <link rel="stylesheet" href="./style.css" />

    <script type="importmap">
    {
      "imports": {
        "lit": "https://esm.run/lit"
      }
    }
    </script>
    <script type="module" src="../../../../bootstrap.js"></script>
  </head>

  <body>
    <site-page>
      <main class="feature-page" id="main" tabindex="-1">

        <!-- Hero -->
        <header class="feature-hero" aria-labelledby="feature-title">
          <div class="feature-page__inner feature-hero__inner">
            <p class="feature-hero__kicker">Feature</p>

            <h1 class="feature-hero__title" id="feature-title">Interpretive Entitlement</h1>

            <p class="feature-hero__lede">
              Interpretation is not free. It’s a permissioned act.
              Interpretive Entitlement formalizes <em>when</em> an interpretation may be asserted and used by requiring
              explicit warrants—what assumptions were invoked, what evidence supports them, and what would falsify them.
            </p>

            <!-- Attention grabber "comic bubble" quotes (web-friendly) -->
            <section class="feature-hero__bubbles" aria-label="Attention quotes">
              <div class="bubble bubble--left">
                <p class="bubble__speaker">Operator</p>
                <p class="bubble__text">“The chart is green. Are we actually entitled to act?”</p>
              </div>

              <div class="bubble bubble--right">
                <p class="bubble__speaker">Vendor</p>
                <p class="bubble__text">“Only if the warrants hold. Otherwise we’re just automating a story.”</p>
              </div>
            </section>

            <!-- Quick bullets -->
            <ul class="feature-hero__bullets" aria-label="Key outcomes">
              <li><strong>Stops self-authorizing loops:</strong> no more “the output proves the assumptions.”</li>
              <li><strong>Makes meaning explicit:</strong> warrants + falsifiers + scope travel with the result.</li>
              <li><strong>Safer automation:</strong> actions trigger only when the interpretation is entitled.</li>
            </ul>
          </div>
        </header>

        <!-- Core sections -->
        <section class="feature-section" aria-labelledby="what-title">
          <div class="feature-page__inner">
            <h2 class="feature-section__title" id="what-title">What it does</h2>

            <p class="feature-section__text">
              Interpretive Entitlement turns a result from <strong>“a story we like”</strong> into a claim with terms.
              Every interpretation ships with its dependencies made explicit.
            </p>

            <div class="feature-cards" role="list">
              <article class="feature-card" role="listitem" aria-labelledby="warrants-title">
                <h3 class="feature-card__title" id="warrants-title">
                  <i class="fa-solid fa-file-signature" aria-hidden="true"></i>
                  Warrants
                </h3>
                <p class="feature-card__text">
                  The assumptions required for the interpretation to be meaningful
                </p>
              </article>

              <article class="feature-card" role="listitem" aria-labelledby="falsifiers-title">
                <h3 class="feature-card__title" id="falsifiers-title">
                  <i class="fa-solid fa-triangle-exclamation" aria-hidden="true"></i>
                  Falsifiers
                </h3>
                <p class="feature-card__text">
                  Conditions that would invalidate the interpretation
                </p>
              </article>

              <article class="feature-card" role="listitem" aria-labelledby="scope-title">
                <h3 class="feature-card__title" id="scope-title">
                  <i class="fa-solid fa-bullseye" aria-hidden="true"></i>
                  Scope
                </h3>
                <p class="feature-card__text">
                  The exact window, dataset segment, and configuration the claim applies to.
                  Outside that scope, the system downgrades the claim instead of pretending.
                </p>
              </article>
            </div>

            <p class="feature-section__text">
              If the warrants don’t hold, the system doesn’t pretend. It <strong>withholds entitlement</strong> or
              <strong>downgrades</strong> the claim.
            </p>
          </div>
        </section>

        <section class="feature-section" aria-labelledby="why-title">
          <div class="feature-page__inner">
            <h2 class="feature-section__title" id="why-title">Why this matters</h2>

            <p class="feature-section__text">
              Most operational failures aren’t caused by missing data. They’re caused by <strong>unearned meaning</strong>.
              A calm chart can be real and still misleading. A clean KPI can be true and still irrelevant.
              A fused number can be precise and still wrong where failure happens.
            </p>

            <div class="feature-callout" role="note" aria-label="Callout">
              <p class="feature-callout__title">
                <i class="fa-solid fa-quote-left" aria-hidden="true"></i>
                Confidence by formatting is not correctness.
              </p>
              <p class="feature-callout__text">
                Interpretive Entitlement replaces “trust me” with permission-by-evidence.
              </p>
            </div>
          </div>
        </section>

        <section class="feature-section" aria-labelledby="practice-title">
          <div class="feature-page__inner">
            <h2 class="feature-section__title" id="practice-title">How it shows up in practice</h2>

            <p class="feature-section__text">
              When a pipeline produces an output, the platform emits:
            </p>

            <ol class="feature-steps">
              <li class="feature-steps__item">
                <strong>The interpretation</strong> (what is being asserted)
              </li>
              <li class="feature-steps__item">
                <strong>The warrants</strong> (what must be true for the interpretation to be valid)
              </li>
              <li class="feature-steps__item">
                <strong>The falsification hooks</strong> (how to test whether the warrants still hold)
              </li>
              <li class="feature-steps__item">
                <strong>The receipt</strong> (checks + identifiers needed to reproduce the entitlement decision)
              </li>
            </ol>

            <div class="feature-compare" aria-label="Before and after framing">
              <div class="feature-compare__col">
                <p class="feature-compare__label">Instead of debating</p>
                <p class="feature-compare__quote">“Which sensor is right?”</p>
              </div>
              <div class="feature-compare__arrow" aria-hidden="true">
                <i class="fa-solid fa-arrow-right"></i>
              </div>
              <div class="feature-compare__col">
                <p class="feature-compare__label">You can ask</p>
                <p class="feature-compare__quote">“Which warrants fail—and is this claim still entitled?”</p>
              </div>
            </div>

            <!-- Tiny “receipt” example (illustrative) -->
            <section class="feature-receipt" aria-labelledby="receipt-title">
              <h3 class="feature-receipt__title" id="receipt-title">
                Example receipt (illustrative)
              </h3>
              <pre class="feature-receipt__code" aria-label="Example receipt">
Interpretation: "Zone 3 stable; safe to tighten setpoint"
Scope: window=W(2026-01-08T14:00..14:10), config=cfg_81F2

Warrants:
- Comparability(A,B) holds on W
- Regime stable on W
- Selection stable under candidate set M

Falsifiers:
- Drift &gt; tol on W
- Pocket signature near boundary seam
- Selection instability across M

Decision:
- Entitled = NO
- Reason: comparability warrant failed; pocket signature detected</pre>
              <p class="feature-receipt__hint">
                The point: downstream teams can reproduce the same entitlement decision without trusting a black box.
              </p>
            </section>
          </div>
        </section>

        <section class="feature-section" aria-labelledby="benefit-title">
          <div class="feature-page__inner">
            <h2 class="feature-section__title" id="benefit-title">The operator benefit</h2>

            <div class="feature-cards feature-cards--wide" role="list">
              <article class="feature-card" role="listitem">
                <h3 class="feature-card__title">
                  <i class="fa-solid fa-ban" aria-hidden="true"></i>
                  Fewer self-authorizing loops
                </h3>
                <p class="feature-card__text">
                  You can’t justify assumptions using the output those assumptions create.
                </p>
              </article>

              <article class="feature-card" role="listitem">
                <h3 class="feature-card__title">
                  <i class="fa-solid fa-people-arrows" aria-hidden="true"></i>
                  Cleaner handoffs
                </h3>
                <p class="feature-card__text">
                  Downstream teams can see exactly what the result means.
                </p>
              </article>

              <article class="feature-card" role="listitem">
                <h3 class="feature-card__title">
                  <i class="fa-solid fa-shield-halved" aria-hidden="true"></i>
                  Safer automation
                </h3>
                <p class="feature-card__text">
                  Actions trigger only when the interpretation is entitled.
                </p>
              </article>

              <article class="feature-card" role="listitem">
                <h3 class="feature-card__title">
                  <i class="fa-solid fa-bug-slash" aria-hidden="true"></i>
                  Faster diagnosis
                </h3>
                <p class="feature-card__text">
                  When something changes, the platform tells you which warrant broke.
                </p>
              </article>
            </div>
          </div>
        </section>

        <section class="feature-section feature-section--tight" aria-labelledby="core-title">
          <div class="feature-page__inner">
            <h2 class="feature-section__title" id="core-title">The core idea</h2>

            <div class="feature-core">
              <p class="feature-core__headline">
                Trustworthy measurement 
                <strong>are backed by warrants and falsifiers you can inspect.</strong>
              </p>
              <p class="feature-core__text">
                Interpretive Entitlement turns interpretation into a checkable contract.
                
              </p>
            </div>
          </div>
        </section>

        <!-- ========================================================= -->
        <!-- CASE STUDY (ADDED)                                        -->
        <!-- ========================================================= -->
        <section class="feature-section" aria-labelledby="case-study-title">
          <div class="feature-page__inner">
            <h2 class="feature-section__title" id="case-study-title">
              Fictitious case study (that certainly couldn’t happen in your company)
            </h2>

            <p class="feature-section__text">
              <strong>Scenario:</strong> “Misplaced sensors” become a license to automate.
              A company decides to “tighten up” environmental control. 
              Not by understanding the room, of course, but by
              adding sensors and buying a slick dashboard that promises “actionable intelligence.”
            </p>

            <div class="feature-callout" role="note" aria-label="Case setup">
              <p class="feature-callout__title">
                The rollout plan is simple:
              </p>
              <ul class="feature-list">
                <li>mount sensors quickly,</li>
                <li>wire them up,</li>
                <li>pick a KPI,</li>
                <li>automate control moves,</li>
                <li>enjoy the calm green glow of competence.</li>
              </ul>
            </div>

            <p class="feature-section__text">
              They ship the system, tune it until the charts look stable, and declare victory the first time the KPI stays green for a week.
              The flagship output is: <strong>StabilityScore = 0.97</strong> <em>(green, with confidence bars)</em>.
              At this point, a manager says the magic phrase:
              <span class="feature-quote-inline">“Looks validated. Let’s automate the action.”</span>
              And just like that, placement becomes policy.
            </p>

            <h3 class="feature-subtitle">What quietly happened (a.k.a. the self-authorizing loop)</h3>
            <p class="feature-section__text">
              To get that clean KPI, the system made a few “minor” decisions—none of which were treated as assumptions.
            </p>

            <ol class="feature-steps feature-steps--compact">
              <li class="feature-steps__item">
                <strong>It treated sensor placement as ground truth.</strong>
                Two sensors were mounted where it was convenient: near a supply stream (great numbers, always “fresh”),
                and near a return path or doorway (numbers that swing, alarms that annoy). Nobody wrote down what those
                locations mean in airflow terms. The dashboard just absorbed them as “the room.”
              </li>
              <li class="feature-steps__item">
                <strong>It assumed sensors were comparable.</strong>
                Same room, same story, right? Except one sensor is measuring the supply’s opinion and the other is measuring the boundary’s complaint.
              </li>
              <li class="feature-steps__item">
                <strong>It optimized for calm.</strong>
                Disagreement is messy. So the pipeline “helped”: smoothing, fusing, outlier filtering, and “confidence weighting”
                (a polite name for choosing a favorite sensor).
              </li>
              <li class="feature-steps__item">
                <strong>It selected the interpretation that stayed green.</strong>
                When the data didn’t agree, the system didn’t ask “what does this imply about the field?” It asked “which model makes this look stable?”
              </li>
              <li class="feature-steps__item">
                <strong>It shipped the conclusion as “what the data says.”</strong>
                But what the data said was: “Your sensors are in different realities.” None of this was labeled as a warrant.
                It was just baked into the output.
              </li>
            </ol>

            <h3 class="feature-subtitle">Then reality happened (in the most boring way possible)</h3>
            <p class="feature-section__text">
              Nothing exploded. No dramatic outage. No instant alarm storm. Instead, the room behaved like a room:
              a pocket formed near a boundary seam, a drift occurred under a seasonal load pattern, and a control action
              “fixed” the sensor near supply while making the pocket worse elsewhere. The KPI stayed green. The outcome got worse.
            </p>

            <h3 class="feature-subtitle">The predictable response</h3>
            <p class="feature-section__text">
              The team does what teams always do when the dashboard is persuasive: blame the “bad sensor,” move probes until alarms stop,
              recalibrate until disagreement looks polite, widen thresholds, add another sensor. Eventually, the postmortem produces:
              <span class="feature-quote-inline">“Everything was in range.”</span>
              Translation: everything was in range where the favored sensor lived.
            </p>

            <h3 class="feature-subtitle">The part they missed: entitlement was never earned</h3>
            <div class="feature-grid feature-grid--2">
              <div class="feature-panel">
                <h4 class="feature-panel__title">Warrants (what must be true)</h4>
                <ul class="feature-list">
                  <li>sensor placement is representative of the zones we claim to control,</li>
                  <li>readings are comparable (not measuring different airflow regimes),</li>
                  <li>the environment is coherent enough on the chosen window,</li>
                  <li>the selected interpretation is stable under plausible placement/mode changes.</li>
                </ul>
              </div>

              <div class="feature-panel">
                <h4 class="feature-panel__title">Falsifiers (what breaks the story)</h4>
                <ul class="feature-list">
                  <li>persistent structured disagreement consistent with zone differences,</li>
                  <li>placement sensitivity (moving a probe “changes reality”),</li>
                  <li>pocket signatures near boundaries / seams,</li>
                  <li>regime shifts under modes (fan staging, doors, load cycles),</li>
                  <li>selection instability (the “best” interpretation changes when you nudge assumptions).</li>
                </ul>
              </div>
            </div>

            <div class="feature-callout" role="note" aria-label="Scope note">
              <p class="feature-callout__title">Scope (where/when it applies)</p>
              <p class="feature-callout__text">
                “This claim is entitled only for these zones, these modes, this placement geometry, and this window.”
              </p>
            </div>

            <h3 class="feature-subtitle">Same story, with Interpretive Entitlement</h3>
            <p class="feature-section__text">
              Now replay the same deployment, but with entitlement. The KPI ships with a placement warrant:
              which sensors represent which zones; what comparability means (and when it fails); and what would falsify
              “room-level stability.” The system sees placement sensitivity, zone structure, and pocket signatures—so instead
              of “green = go,” it downgrades the claim:
            </p>

            <pre class="feature-receipt__code" aria-label="Entitlement downgrade example">
Decision:
- Entitled = NO
- Reason: comparability warrant failed; placement not representative; zone structure detected;
          “room average” interpretation out of scope</pre>

            <p class="feature-section__text">
              And suddenly the dashboard stops being persuasive and starts being honest. The operator conversation changes from politics to engineering:
              <strong>“Which placement warrant failed—and what placement or zoning change restores entitlement?”</strong>
            </p>

            <h3 class="feature-subtitle">Takeaway</h3>
            <p class="feature-section__text">
              If a system cannot state what placement assumptions it’s making, what scope those assumptions apply to, and what would falsify them,
              then it isn’t measuring the room. It’s measuring the convenience of where you mounted the probes.
              Interpretive Entitlement is how you stop “misplaced sensors + a green KPI” from becoming automatic permission to act—and start treating
              interpretation as what it is: <strong>a permissioned act.</strong>
            </p>

          </div>
        </section>
      </main>
    </site-page>
  </body>
</html>
